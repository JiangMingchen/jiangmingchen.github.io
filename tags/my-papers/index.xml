<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>my papers on Mingchen Jiang</title><link>https://jiangmingchen.github.io/tags/my-papers/</link><description>Recent content in my papers on Mingchen Jiang</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Copyright © 2008–2019, Steve Francia and the lee.so; all rights reserved.</copyright><lastBuildDate>Fri, 22 Sep 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://jiangmingchen.github.io/tags/my-papers/index.xml" rel="self" type="application/rss+xml"/><item><title>[Paper Accepted]One Paper is Accepted by NeurIPS 2023!</title><link>https://jiangmingchen.github.io/post/neurips2023/</link><pubDate>Fri, 22 Sep 2023 00:00:00 +0000</pubDate><guid>https://jiangmingchen.github.io/post/neurips2023/</guid><description>Abstract Compositionality facilitates the comprehension of novel objects using acquired concepts and the maintenance of a knowledge pool. This is particularly crucial for continual learners to prevent catastrophic forgetting and enable compositionally forward transfer of knowledge. However, the existing state-of-the-art benchmarks inadequately evaluate the capability of compositional generalization, leaving an intriguing question unanswered. To comprehensively assess this capability, we introduce two vision benchmarks, namely Compositional GQA (CGQA) and Compositional OBJects365 (COBJ), along with a novel evaluation framework called Compositional Few-Shot Testing (CFST).</description></item></channel></rss>